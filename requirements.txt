# === Core Web Framework ===
fastapi==0.115.0
uvicorn[standard]==0.30.0
starlette==0.38.2
fastapi-cors==0.0.6
fastapi-utils==0.8.0


httpx==0.27.2          # async HTTP client (for Llama Stack / vLLM)

# === Model Interaction ===
openai==1.48.0         # compatible client for OpenAI-like APIs (works with vLLM / Llama Stack)
transformers==4.46.0   # for local inference or fallback model
accelerate==0.33.0     # for lightweight GPU acceleration (optional local testing)
torch==2.4.0            # only if fine-tuning or local testing required
vllm==0.5.5             # for RHOAI or Podman local vLLM inference (optional)

orjson==3.10.7         # fast JSON parsing


# deployment 
gunicorn==22.0.0
uvloop==0.20.0

# bonus points
# InstructLab fine-tuning / Granite interaction
instructlab==0.26.1       # Granite retraining pipeline
huggingface_hub==0.25.1  # Model management and uploads
notebook==7.2.2          # For Jupyter on RHOAI
jupyterlab==4.3.1


#  Frontend serving (if React built locally)
jinja2==3.1.4

# Object Storage
minio==7.2.12
# boto3==1.35.57